{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CxvJm0GlxbTu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and load the CIFAR-10 dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esb6O3S8x71u",
        "outputId": "99df59b8-e38c-4e3e-940c-63149560f710"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "X_train = X_train.astype('float32') / 255  # Normalize pixel values between 0 and 1\n",
        "X_test = X_test.astype('float32') / 255\n",
        "y_train = to_categorical(y_train, num_classes=10)  # Convert labels to one-hot encoding\n",
        "y_test = to_categorical(y_test, num_classes=10)"
      ],
      "metadata": {
        "id": "sPpKWJPex-PS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fuzzy_function(kernel):\n",
        "    fuzzy_kernel = np.zeros_like(kernel)\n",
        "\n",
        "    for i in range(kernel.shape[0]):\n",
        "        for j in range(kernel.shape[1]):\n",
        "            mu = 0.5  # Mean\n",
        "            sigma = 0.05  # Standard deviation\n",
        "\n",
        "            for k in range(kernel.shape[2]):\n",
        "                for l in range(kernel.shape[3]):\n",
        "                    weight = kernel[i, j, k, l]\n",
        "                    fuzzy_weight = np.exp(-(weight - mu) * 2 / (2 * sigma * 2))\n",
        "                    fuzzy_kernel[i, j, k, l] = fuzzy_weight\n",
        "\n",
        "    return fuzzy_kernel"
      ],
      "metadata": {
        "id": "pqm8l1RGyAcC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom activation layer implementing min(1-a, b)\n",
        "class MinOneMinusAActivation(keras.layers.Conv2D):\n",
        "    def __init__(self, filters, kernel_size, **kwargs):\n",
        "        super(MinOneMinusAActivation, self).__init__(filters, kernel_size, **kwargs)\n",
        "\n",
        "    def activation(self, x):\n",
        "        fuzzy_kernel = fuzzy_function(self.kernel)\n",
        "        return K.minimum(1 - x, fuzzy_kernel)"
      ],
      "metadata": {
        "id": "8t7n_W10yIIp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom activation layer implementing max(1-a, b)\n",
        "class MaxOneMinusAActivation(keras.layers.Conv2D):\n",
        "    def __init__(self, filters, kernel_size, **kwargs):\n",
        "        super(MaxOneMinusAActivation, self).__init__(filters, kernel_size, **kwargs)\n",
        "\n",
        "    def activation(self, x):\n",
        "        fuzzy_kernel = fuzzy_function(self.kernel)\n",
        "        return K.maximum(1 - x, fuzzy_kernel)"
      ],
      "metadata": {
        "id": "EP1WQ-AsyLYE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom activation function implementing fuzzy thresholding\n",
        "def fuzzy_threshold(x):\n",
        "    return K.maximum(K.minimum(x, 1), 0)"
      ],
      "metadata": {
        "id": "fXGkFbveyODf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom activation function implementing fuzzy softmax\n",
        "def fuzzy_softmax(x):\n",
        "    max_val = K.max(x, axis=-1, keepdims=True)\n",
        "    e = K.exp(x - max_val)\n",
        "    s = K.sum(e, axis=-1, keepdims=True)\n",
        "    return e / s"
      ],
      "metadata": {
        "id": "FQZalYEoyRn_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sequential model\n",
        "model = keras.models.Sequential()\n",
        "# Add Conv2D layers with custom activations\n",
        "model.add(MinOneMinusAActivation(32, kernel_size=(3, 3), activation=fuzzy_threshold, input_shape=(32, 32, 3)))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(MaxOneMinusAActivation(32, kernel_size=(3, 3), activation=fuzzy_threshold))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))  # Add Dropout layer\n",
        "\n",
        "model.add(keras.layers.Flatten())\n",
        "\n",
        "# Add fully connected layers for classification\n",
        "model.add(keras.layers.Dense(256, activation=fuzzy_threshold))\n",
        "model.add(keras.layers.Dense(128, activation=fuzzy_threshold))\n",
        "model.add(keras.layers.Dense(64, activation=fuzzy_threshold))\n",
        "model.add(keras.layers.Dense(10, activation=fuzzy_softmax))"
      ],
      "metadata": {
        "id": "kjOAHYKQyYBc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Compile the model using categorical cross-entropy as loss (not fuzzy loss for simplicity)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(datagen.flow(X_train, y_train, batch_size=256),\n",
        "                    epochs=30,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    verbose=1,\n",
        "                    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BmMbYn4ybZ3",
        "outputId": "00dfbe09-6953-49b3-bf8e-60d85ee35924"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "196/196 [==============================] - 96s 472ms/step - loss: 1.7852 - accuracy: 0.3460 - val_loss: 1.5041 - val_accuracy: 0.4634\n",
            "Epoch 2/30\n",
            "196/196 [==============================] - 87s 443ms/step - loss: 1.5282 - accuracy: 0.4445 - val_loss: 1.3947 - val_accuracy: 0.5048\n",
            "Epoch 3/30\n",
            "196/196 [==============================] - 88s 450ms/step - loss: 1.4299 - accuracy: 0.4822 - val_loss: 1.2951 - val_accuracy: 0.5387\n",
            "Epoch 4/30\n",
            "196/196 [==============================] - 87s 438ms/step - loss: 1.3596 - accuracy: 0.5089 - val_loss: 1.2368 - val_accuracy: 0.5580\n",
            "Epoch 5/30\n",
            "196/196 [==============================] - 87s 441ms/step - loss: 1.3048 - accuracy: 0.5323 - val_loss: 1.1486 - val_accuracy: 0.5963\n",
            "Epoch 6/30\n",
            "196/196 [==============================] - 84s 430ms/step - loss: 1.2640 - accuracy: 0.5510 - val_loss: 1.1048 - val_accuracy: 0.6088\n",
            "Epoch 7/30\n",
            "196/196 [==============================] - 84s 428ms/step - loss: 1.2254 - accuracy: 0.5610 - val_loss: 1.0437 - val_accuracy: 0.6302\n",
            "Epoch 8/30\n",
            "196/196 [==============================] - 84s 427ms/step - loss: 1.1958 - accuracy: 0.5753 - val_loss: 1.0150 - val_accuracy: 0.6458\n",
            "Epoch 9/30\n",
            "196/196 [==============================] - 84s 427ms/step - loss: 1.1721 - accuracy: 0.5837 - val_loss: 1.0187 - val_accuracy: 0.6438\n",
            "Epoch 10/30\n",
            "196/196 [==============================] - 84s 429ms/step - loss: 1.1446 - accuracy: 0.5933 - val_loss: 0.9548 - val_accuracy: 0.6682\n",
            "Epoch 11/30\n",
            "196/196 [==============================] - 87s 441ms/step - loss: 1.1255 - accuracy: 0.5990 - val_loss: 0.9462 - val_accuracy: 0.6693\n",
            "Epoch 12/30\n",
            "196/196 [==============================] - 85s 435ms/step - loss: 1.1101 - accuracy: 0.6054 - val_loss: 0.9085 - val_accuracy: 0.6819\n",
            "Epoch 13/30\n",
            "196/196 [==============================] - 85s 435ms/step - loss: 1.0913 - accuracy: 0.6123 - val_loss: 0.9144 - val_accuracy: 0.6812\n",
            "Epoch 14/30\n",
            "196/196 [==============================] - 83s 423ms/step - loss: 1.0761 - accuracy: 0.6181 - val_loss: 0.9918 - val_accuracy: 0.6480\n",
            "Epoch 15/30\n",
            "196/196 [==============================] - 82s 420ms/step - loss: 1.0513 - accuracy: 0.6269 - val_loss: 0.9288 - val_accuracy: 0.6770\n",
            "Epoch 16/30\n",
            "196/196 [==============================] - 83s 424ms/step - loss: 1.0411 - accuracy: 0.6294 - val_loss: 0.9759 - val_accuracy: 0.6717\n",
            "Epoch 17/30\n",
            "196/196 [==============================] - 84s 426ms/step - loss: 1.0262 - accuracy: 0.6353 - val_loss: 0.9016 - val_accuracy: 0.6828\n",
            "Epoch 18/30\n",
            "196/196 [==============================] - 85s 433ms/step - loss: 1.0129 - accuracy: 0.6414 - val_loss: 0.8559 - val_accuracy: 0.7000\n",
            "Epoch 19/30\n",
            "196/196 [==============================] - 84s 427ms/step - loss: 1.0142 - accuracy: 0.6400 - val_loss: 0.8801 - val_accuracy: 0.6912\n",
            "Epoch 20/30\n",
            "196/196 [==============================] - 86s 437ms/step - loss: 0.9992 - accuracy: 0.6472 - val_loss: 0.8940 - val_accuracy: 0.6904\n",
            "Epoch 21/30\n",
            "196/196 [==============================] - 85s 431ms/step - loss: 0.9866 - accuracy: 0.6518 - val_loss: 0.9514 - val_accuracy: 0.6666\n",
            "Epoch 22/30\n",
            "196/196 [==============================] - 83s 423ms/step - loss: 0.9861 - accuracy: 0.6510 - val_loss: 0.8935 - val_accuracy: 0.6925\n",
            "Epoch 23/30\n",
            "196/196 [==============================] - 84s 428ms/step - loss: 0.9823 - accuracy: 0.6529 - val_loss: 0.8542 - val_accuracy: 0.7070\n",
            "Epoch 24/30\n",
            "196/196 [==============================] - 85s 431ms/step - loss: 0.9619 - accuracy: 0.6602 - val_loss: 0.8454 - val_accuracy: 0.7039\n",
            "Epoch 25/30\n",
            "196/196 [==============================] - 84s 429ms/step - loss: 0.9545 - accuracy: 0.6634 - val_loss: 0.8243 - val_accuracy: 0.7111\n",
            "Epoch 26/30\n",
            "196/196 [==============================] - 84s 429ms/step - loss: 0.9490 - accuracy: 0.6666 - val_loss: 0.8527 - val_accuracy: 0.7006\n",
            "Epoch 27/30\n",
            "196/196 [==============================] - 85s 433ms/step - loss: 0.9430 - accuracy: 0.6657 - val_loss: 0.8520 - val_accuracy: 0.7033\n",
            "Epoch 28/30\n",
            "196/196 [==============================] - 84s 426ms/step - loss: 0.9353 - accuracy: 0.6690 - val_loss: 0.9278 - val_accuracy: 0.6819\n",
            "Epoch 29/30\n",
            "196/196 [==============================] - 85s 431ms/step - loss: 0.9332 - accuracy: 0.6709 - val_loss: 0.8078 - val_accuracy: 0.7188\n",
            "Epoch 30/30\n",
            "196/196 [==============================] - 85s 431ms/step - loss: 0.9253 - accuracy: 0.6748 - val_loss: 0.8205 - val_accuracy: 0.7129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Évaluez le modèle sur l'ensemble de test\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
        "\n",
        "# Affichez les résultats\n",
        "print(f'Loss on test set: {loss:.4f}')\n",
        "print(f'Accuracy on test set: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "id": "mZWLMb3ZA3nR",
        "outputId": "e2e3eddf-8121-40fc-d3db-f07ede5bc6dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 6s 19ms/step - loss: 0.8205 - accuracy: 0.7129\n",
            "Loss on test set: 0.8205\n",
            "Accuracy on test set: 71.29%\n"
          ]
        }
      ]
    }
  ]
}